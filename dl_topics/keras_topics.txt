comparison of ddep learning frameworks

https://skymind.ai/wiki/comparison-frameworks-dl4j-tensorflow-pytorch


--tensorflow vs. caffe
https://www.educba.com/tensorflow-vs-caffe/


tensors-

https://www.easy-tensorflow.com/tf-tutorials/basics/graph-and-session

--take aways

a Tensor is a multi-dimensional array (0-D tensor: scalar, 1-D tensor: vector, 2-D tensor: matrix, and so on).



sessions-

https://danijar.com/what-is-a-tensorflow-session/




kernels -
https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/


filters -
https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/


strides-


activation functions-
https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/

--importance of activation functions
https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f


convolutions 1d-

--examples
https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf


convolutions 2d-
https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/
https://missinglink.ai/guides/keras/keras-conv2d-working-cnn-2d-convolutions-keras/

--peer reviewed articles
https://arxiv.org/pdf/1603.07285.pdf

--examples-to-look-at
https://blog.xrds.acm.org/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/


dialated convolutions-

https://stackoverflow.com/questions/41178576/whats-the-use-of-dilated-convolutions

--peer reviewed articles
https://arxiv.org/pdf/1511.07122.pdf
https://arxiv.org/pdf/1609.03499.pdf

--take aways
Pooling and Strided Convolutions are similar concepts but both reduce the resolution.


receptive fields-

https://www.quora.com/What-is-a-receptive-field-in-a-convolutional-neural-network
https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807
https://distill.pub/2019/computing-receptive-fields/

--take aways

equivalent to filter size


max-pooling-
https://computersciencewiki.org/index.php/Max-pooling_/_Pooling

--take aways
This is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn and provides basic translation invariance to the internal representation.

Max pooling is done by applying a max filter to (usually) non-overlapping subregions of the initial representation.


channels-first/channels-last
https://machinelearningmastery.com/a-gentle-introduction-to-channels-first-and-channels-last-image-formats-for-deep-learning/

--take aways
each deep learning framework has its own placement on where they want channel, look at how that one need. Keras is last by default


one-hot-
https://en.wikipedia.org/wiki/One-hot
https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/
https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/

--take away
if the ordering tells something about a categorical variable it may help to use interger incoding


batch size-

https://forums.fast.ai/t/please-explain-why-batch-size-matters/9045

--take aways
increase by powers of two in order to include enough of the data too give information, but so much that you overfit


exercises that might be helpful-
https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/

decent starting websites-
https://machinelearningmastery.com/
https://towardsdatascience.com/

deep learning books-
http://www.deeplearningbook.org/


